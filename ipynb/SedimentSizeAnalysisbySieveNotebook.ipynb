{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sediment Size Analysis by Sieve (SedSAS) Class - Notebook Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part I: Introduction:\n",
    "\n",
    "SedSAS is a class object written in the Python programming (scripting) language. Its purpose is to provide a set of software-based statistical and visualization tools for analyzing unconsolidated sediment size-fraction samples separated using either mechanical sieves or other analog partition-by-size methods. It should be made clear at the outset that SedSAS is not a standalone application. Rather, as a class it provides a core set of methods from which, with some additional Python coding, a fully functional tool for sediment particle size analysis can be crafted. \n",
    "\n",
    "Fortunately, the amount of additional coding required to build SedSAS into a functional particle size-analysis system is small and relatively easy to realize. This ease is demonstrated in a set of Jupyter notebooks found elsewhere in this repository. The interested reader is encouraged to visit, download, study, and experiment with these notebooks to get a feel for how they might use SedSAS in their own investigations. The current notebook provides a descriptive reference for the class: what specifically SedSAS does and how it does it. \n",
    "\n",
    "The class itself is packaged as a single Python script: SedSASClass.py. It can be viewed and downloaded from this repository.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can the SedSAS class do:\n",
    "\n",
    "**From a set of fractional weights compiled from sediment partitioned by size (via mechanical sieving or similar), the methods in the SedSAS Class can do the following:**\n",
    "- compute weight percentages and cumulative weight percentages for each fraction relative to the total sample\n",
    "- compute the mean, sorting (standard deviation), skewness, and kurtosis for each sample using two established methodologies: inclusive graphics and method of moments. Inclusive graphics (Folk and Ward, 1957; Folk, 1980) consist of the classic logarithmic and the lesser-used geometric approaches. Method of Moments computations (Krumbien and Pettijjohn, 1938) include the arithmetic, geometric, and logarithmic techniques. \n",
    "- locate the distribution's mode(s), up to the first three.\n",
    "- assigned textural descriptors to the results as per Folk and Ward (1957), Udden (1922), ad Krumbien and Pettijohn (1938).\n",
    "- generate a histogram (bins=#sieves) with frequency curve and cumulative frequency curve for sample weight percentages and cumulative weight percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computational Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.) Inclusive Graphics: (Folk and Ward, 1957 and Folk, 1980)\n",
    "\n",
    "[Class Method: ComputeFWLogInclusiveGraphicStats()]\n",
    "\n",
    "##### (per ):\n",
    "_This is the most commonly used particle size analysis method_\n",
    "\n",
    "$$ \\text{mean}= M_z= { \\phi_{16} + \\phi_{50}+\\phi_{84} \\over 3 } $$\n",
    "<br>\n",
    "$$ \\text{standard deviation (sorting)} = \\sigma_{i\\phi} = {\\phi_{16} + \\phi_{84} \\over 4} + {\\phi_{95} - \\phi_{5} \\over 6.6 } $$\n",
    "<br>\n",
    "$$ \\text{inclusive skewness} = sk = {\\phi_{16} + \\phi_{84} - 2\\phi_{50} \\over 2(\\phi_{84} - \\phi_{16}) } + {\\phi_{5} + \\phi_{95} - 2\\phi_{50} \\over 2(\\phi_{95} - \\phi_{5}) } $$\n",
    "<br>\n",
    "$$ \\text{kurtosis} = K = {\\phi_{95} - \\phi_{5} \\over 2.44(\\phi_{75} - \\phi_{25}) } $$ \n",
    "\n",
    "\n",
    "Units: $\\phi$\n",
    "( $\\phi = -log_2 d$ where d is the particle diameter in millimeters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.) Inclusive Graphics: McCammon High-Efficiency: (McCammon, 1963)\n",
    "\n",
    "[Class Method: ComputeMcCammonHiEffGraphicStats()]\n",
    "\n",
    "$$ \\text{mean}= M_z= { \\phi_{5} + \\phi_{15}+\\phi_{25}+\\phi_{35} + \\phi_{45}+\\phi_{55}+\\phi_{65} + \\phi_{75}+\\phi_{85}+\\phi_{95} \\over 10 } $$\n",
    "<br>\n",
    "$$ \\text{standard deviation (sorting)} = \\sigma_{i\\phi} = {{\\phi_{70} + \\phi_{80}+\\phi_{90}+\\phi_{97}-\\phi_{3}-\\phi_{10}-\\phi_{20}-\\phi_{30}} \\over 9.1} $$\n",
    "<br>\n",
    "\n",
    "Units: $\\phi$\n",
    "( $\\phi = -log_2 d$ where d is the particle diameter in millimeters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.) Method of Moments: (Friedman, 1962)\n",
    "\n",
    "[Class method: ComputeArithmeticMethodofMomentStats()]\n",
    "\n",
    "$$ \\text{mean (M)} \\enspace = {\\sum{D_mW_f} \\over \\sum{W_f} }  $$\n",
    "<br><br>\n",
    "$$ \\text{standard deviation (sorting)} \\enspace (\\sigma) = \\sqrt{\\sum{[W_f(D_m-M)^2] } \\over \\sum{W_f}} $$\n",
    "<br><br>\n",
    "$$ \\text{skewness} = {\\sum{[W_f(D_m-M)^3] } \\over (\\sum{W_f}) \\sigma^3} $$\n",
    "<br><br>\n",
    "$$ \\text{kurtosis} = {\\sum{[W_f(D_m-M)^4] } \\over (\\sum{W_f}) \\sigma^4} $$\n",
    "**where:**<br>\n",
    "- $D_m$ = size-class fraction (bin) mid-point <br>\n",
    "- $W_f$ = size-class fraction weight percentage <br>\n",
    "- $M$ = the computed method of moments mean (units=millimeters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 4.) Method of Moments: (Blott and Pye, 2001)\n",
    "\n",
    "[Class method: ComputeLogarithmicMethodofMomentStats()]\n",
    "\n",
    "$$ \\text{mean (M)} \\enspace = {\\sum{D_{m\\phi}W_f} \\over \\sum{W_f} }  $$\n",
    "<br><br>\n",
    "$$ \\text{standard deviation (sorting)} \\enspace (\\sigma) = \\sqrt{\\sum{[W_f(D_{m\\phi}-M)^2] } \\over \\sum{W_f}} $$\n",
    "<br><br>\n",
    "$$ \\text{skewness} = {\\sum{[W_f(D_{m\\phi}-M)^3] } \\over (\\sum{W_f}) \\sigma^3} $$\n",
    "<br><br>\n",
    "$$ \\text{kurtosis} = {\\sum{[W_f(D_{m\\phi}-M)^4] } \\over (\\sum{W_f}) \\sigma^4} $$\n",
    "**where:**<br>\n",
    "- $D_{m\\phi}$ = size-class fraction (bin) mid-point (units=$\\phi$)<br>\n",
    "- $W_f$ = size-class fraction weight percentage <br>\n",
    "- $M$ = the computed method of moments mean (units=$ \\phi $)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "1. Folk, R. 1980. Petrology of Sedimentary Rocks. Hemphill Publishing Company, Austin, TX. 184p.\n",
    "2. Folk and Ward, 1957.\n",
    "3. Inman, 1952.\n",
    "4. Krumbien  1934.\n",
    "5. Krumbien and Pettijohn, 1938."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II Using the SedSAS Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Guide to understanding and using SedSAS:<a name=\"Guide\"></a>\n",
    "\n",
    "This is a basic but hopefully sufficient guide to setting up and using SedSAS for analyzing sediment sample data. Click on the links to navigate the notebook.\n",
    "\n",
    "- #### Preliminaries:\n",
    "    - Required Python (Part I): The SedSAS class module file SedSAS.py, this notebook, and all supporting materials were developed in a Python 3.x environment. Neither the module nor any of these supporting materials have been tested using a Python 2.x distro. *Backward compatibility is expected, but not assured.*\n",
    "    \n",
    "    - Required Python (Part II): If you do not have a Python interpreter installed on your computer (frome the factory Linux UNIX, and MacOS users do; Windows users likely do not), your best bet for a trouble-free installation experience can be had here: https://anaconda.org/anaconda/python. If you're more adventurous, try the Python Software Foundation: https://www.python.org/getit/. Even if your OS does come with a Python interpreter already in place, it's probably a good idea to get a more up to date release (most OS installs are a version, or more, behind the current release). Again, we suggest the Anaconda distribution. Be sure to get a copy of Python version 3.5 or later.  \n",
    "    \n",
    "    - [Required external Python Libraries and modules](#Required Libraries) List of required installed Python libraries (e.g., numpy, scipy, pandas) needed by SedSAS. Note that these, and many, many other libraries, are included in the Anaconda Python distribution.\n",
    "    \n",
    "    - [User inputs](#User Inputs) Information to be provided by the user, needed to initiate and use the class\n",
    "    \n",
    "    - [Structuring Input Data](#Structuring) This very important step prepares the raw sediment weights data for loading into the pandas data frame that will passed to SedSAS at instantiation. \n",
    "\n",
    "    - [Reading the source data into the pandas data frame](#Readingthesource): Various means (not exhaustive) of loading source data into a dataframe.\n",
    "    \n",
    "    - [Creating a SedSAS class instance](#instantiatingclass): creating an instance of the SedSAS class. You must create this instance before you can call any of the methods that follow.\n",
    "    \n",
    "- #### Class Methods:\n",
    "    - User-callable Computational Methods:\n",
    "        - [ComputeGSStats](#convenience): a convenience method that combines processes from three of the four user-callable computational methods listed below: ComputeFWLogInclusiveGraphicsStats(), ComputeMcCammonHiEffGraphicStats(), and ComputeLogarithmicMethodofMomentsStats(). The option to return textural descriptions is set to True. Finally, modes are returned via the method FindSampleModes(). Use this method to quickly and relatively easily analyze large numbers of samples, and generate useful statistics, with minimal coding.\n",
    "<br>\n",
    "        - [ComputeFWLogInclusiveGraphicsStats](#log graphic stats): compute logarithmic inclusive graphical statistics (mean, sorting (standard deviation), skewness, and kurtosis in $\\phi$ units) for the sample data as described by Folk and Ward, 1957, Folk, 1980 and others. Optionally, assigns qualitative textural descriptions for size, sorting, skewness, and kurtosis to sample data.\n",
    "<br>    \n",
    "        - [ComputeMcCammonHiEffGraphicStats](#geom graphic stats): compute inclusive graphical statistics (mean, sorting (standard deviation) only) for the sample data using McCammon's optimized equations (see McCammon, 1963 for a detailed discussion). Optionally, assigns qualitative textural descriptions for size and sorting to sample data. This method was originally, and continues to be, designated as experimental in SedSAS. \n",
    "<br>    \n",
    "        - [ComputeArithmeticMethodofMomentsStats](#arithmetic moment stats): computes the mean, sorting (standard deviation), skewness, and kurtosis (in mm units) for the sample data using the arithmetic method of moments (Friedman, 1962). This method does not provide the option to assign and display textural descriptions to sample data.\n",
    "<br>    \n",
    "\n",
    "        - [ComputeLogarithmicMethodofMomentsStats](#logrithmic moment stats): computes the mean, sorting (standard deviation), skewness, and kurtosis (in $\\phi$ units) for the sample data using the logrithmic method of moments (Blott and Pye, 2001). Optionally, assigns qualitative textural descriptions for size, sorting, skewness, and kurtosis to sample data.\n",
    "<br>    \n",
    "        - [FindSampleModes](#sample modes): locates and reports mode values observed in the sample data\n",
    "    <br><br>\n",
    "    - Plotting Methods:\n",
    "        - [PLOTSampleWtPercents](#plot sample weight percents): generates a histogram and superimposed kernel density estimator of sample weight percentage values.\n",
    "<br>    \n",
    "        - [PLOTSampleCumWtPercents](#plot cum weight percents): generates a cumulative frequency curve (line) of sample weight percentage values.\n",
    "<br>    \n",
    "        - [PLOTDualSampleWeightPercents](#plot dual sample weights): generates both a histogram and superimposed kernel density estimator, and a cumulative frequency curve (line) of sample weight percentage values. This is a convenience method that combines the work of PLOTSampleWtPercents and PLOTSampleCumWtPercents into a single function call.\n",
    "<br><br>\n",
    "    - General Methods:\n",
    "        - [ReturnWeightsData](#ReturnWeightsData): returns a copy to the pandas data frame df that is built in an instance of the  SedSAS class during initialization and is used throughout as data input for subsequent computations and reporting. Use this method if you wish to simply print a copy of the weights data to the console, or to capture that data for use outside of SedSAS.\n",
    "<br>\n",
    "        - [ReturnQuantiles](#ReturnQuantiles) returns a Python list of the interpolated/extrapolated values for the 5th, 10th, 16th, 25th, 50th, 75th, 86th, 90th, and 95th quantiles, based on the CDF. Quantiles units are $\\phi$.\n",
    "<br><br>\n",
    "    - Class Methods not [usually] called by the user. These methods are used (and called) internally, and so the user will generally have no need to call them, but can do so, if desired, to meet a specific need. Refer to the SedSAS.py for guidance on how to use.\n",
    "        - **EstimateQuantileValues**: interpolates/extrapolates the sample data values for quantile values as required by ComputeFWLogInclusiveGraphicsStats(): the 5th, 10th, 16th, 25th, 50th, 75th, 86th, 90th, and 95th quantiles; and for ComputeMcCammonHiEffGraphicStats(): the 3rd, 5th, 10th, 15th, 20th, 25th, 30th, 35th, 45th, 55th, 65th, 70th, 75th, 80th, 85th, 90th, 95th, and 97th quantiles. It calls InterpolateQuantileLinearFit and/or ExtrapolateQuantileLinearFit to produce the estimated quantile values.\n",
    "        - **InterpolateQuantileLinearFit**: Uses simple linear interpolation (between two known cumulative weight points) to estimate quantile values. Called by EstimateQuantileValues.\n",
    "        - **ExtrapolateQuantileLinearFit**: Extends simple linear interpolation to estimates where only one adjacent known point is available. To provide a surrogate second 'known' point SedSAS uses an approach whereby an additional sieve aperture, one size larger--is added to the existing set of sieves. Called by EstimateQuantileValues.\n",
    "        - **ComputePartiallyDeterminedSampleFractions**: Finds the amount of the total sediment fraction in the sample that: 1.) failed to pass through the largest aperture sieve in the stack, and/or 2.) the fraction of the sample that fell into the pan at the bottom of the stack. If either of these values exceeds 5% of the total sample the user is warned about potential impacts on results. Called by __init__ during instantiation.\n",
    "        - **ComputeWeightClassBinMidpoints**: Computes the size midpoint value for each sieve weight class. The weight class is defined by the collection of sieve apertures used in the analysis, as recorded in the 0th column in the internal dataframe. Called by __init__ during instantiation.\n",
    "        - **ClassifyByGrainSize**: Textural Description Group Method. Classifies the resultant particle mean size using Wentworth's sizing scale (Wentworth, 1922 per Folk, 1980)\n",
    "        - **ClassifyLogarithmicSorting**: Textural Description Group Method. Classifies the resultant sorting (standard deviation) value as computed using the method of moments and Folk and Ward inclusive graphics approaches.\n",
    "        - **ClassifyFWLogSkewness**: Textural Description Group Method. Classifies a resultant skewness value as computed using the Folk and Ward (1957) inclusive graphic method.\n",
    "        - **ClassifyMoMLogSkewness**: Textural Description Group Method. Classifies a resultant skewness value as computed using the method of moments method.\n",
    "        - **ClassifyFWKurtosis**: Textural Description Group Method. Classifies a resultant kurtosis value as computed using the Folk and Ward (1957) inclusive graphic method of computation. \n",
    "        - **ClassifyMoMKurtosis**: Textural Description Group Method. Classifies a resultant kurtosis value as computed using the methods of moments computations.\n",
    "<br>    \n",
    "- #### Sample Scripts:\n",
    "    - [Sample Notebooks](#sample scripts): A set of sample Jupyter notebooks purposed to teach, to guide, to use, and even to grow, the Sediment Size Analysis by Sieve class methods stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part III: Using the class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.) Required libraries and modules:<a name=\"Required Libraries\"></a>\n",
    "\n",
    "The SedSASClass will call and attempt to load into the class namespace the following Python libraries:\n",
    "\n",
    "- sys\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib.pyplot\n",
    "\n",
    "These should be installed in your Python environment prior to working with the SedSAS Class. Note that the class itself will call these at instantiation.\n",
    "\n",
    "If your script is in a directory other than the same one where the SedSASClass file itself is stored you will have to amend the system's path variable (only for this namespace and only while the current namespace exists). You can do this with the sys.path.append command:\n",
    "\n",
    "        import sys\n",
    "        sys.path.append(' </path/to/class/location/> ')\n",
    "\n",
    "        import sys\n",
    "        sys.path.append('/Users/Documents/projects/myproject')\n",
    "      \n",
    "        where the SedSASClass.py file resides in the myproject directory\n",
    "        \n",
    "        \n",
    "        \n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### b.) Required User Inputs: <a name=\"User Inputs\"></a>\n",
    "\n",
    "Initial data input to SedSAS during the instantiation process consists of:\n",
    "1. a listing of all the sieve apertures used in the analysis\n",
    "2. the concomitant weight of sediment material captured by each sieve \n",
    "\n",
    "These data must be passed to SedSAS inside a Pandas dataframe where the first column contains the aperture sizes in order as in the actual stack and where the second column contains the associated sediment weight.\n",
    "\n",
    "A unique identifier for the sample can optionally be passed to SedSAS at the time of instantiation. Note that SedSAS doesn't really care if you provide a unique identifier, nor is it particular about how you choose to format the id. The identifier is more for the user and tracking than for code execution and so from a functional point of view, it's not even a requiremment. Nevertheless, it makes sense to provide something that helps to track what's in process, especially if you want to distinguish between samples when multiple samples are run in succession. If you wish to forego an id, the class will assign the default value: '1' as id each time the the class is instantiated.\n",
    "\n",
    "Several Jupyter notebooks are included in this repository that demonstrate the various ways that data can be ingested into SedSAS and processed for analysis.\n",
    "\n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### c.) Structuring the input data <a name=\"Structuring\"></a>\n",
    " \n",
    " Perhaps the most difficult aspect of working with this notebook and the SedSASClass is getting your data into a form that can be passed into the class during instantiation. The reason behind the possible difficulty is that the data, **which you will submit as a Pandas data frame**, needs only select information, probably much less than you captured as part of your lab analyses. Here's what you'll need, as mentioned above, in the dataframe supplied as input to the class during instantiation: \n",
    "\n",
    "1. a list of the sieves (aperture sizes in $\\phi$ units) used. \n",
    "2. individual sieved sample weights. Weights units are assumed to be grams but the actual weight units have no bearing on the computations carried out. Sizes are assumed to be in $\\phi$ units. \n",
    "\n",
    "The dataframe passed to SedSAS will be formatted such that column 1 (the zeroth column using Python's indexing) contains the sieve apertures, and column 2 (Python column index = 1) the sediment weights captured in each sieve:\n",
    "\n",
    "See the example Jupyter notebooks for guidance on preparing data for SedSAS.\n",
    "\n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.) Reading the source data into the pandas data frame <a name=\"Readingthesource\"></a>\n",
    "\n",
    "    # import the pandas module into your script:\n",
    "    import pandas as pd\n",
    "    \n",
    "    # example data sources:\n",
    "    f1='./SampleScripts/DrySieveResults.csv'\n",
    "    f2='./SampleScripts/DrySieveResults.dat'\n",
    "    ss_file='./SampleScripts/SievingData.xlsx'\n",
    "    db_name='./SampleScripts/SieveAnal.db'\n",
    "    tbl_name='SieveResults'\n",
    "    \n",
    "**Example: Pandas dataframe built from a comma separated text file:**<br>\n",
    "\n",
    "    df = pd.read_csv( f1 )\n",
    "    \n",
    "    \n",
    "**Example: Pandas dataframe built from a tab (or other field delimiter) text file**<br>\n",
    "\n",
    "    df = pd.read_table(f2, sep='t' )     # replace 't' with file delimiter, as required.\n",
    "    \n",
    "  \n",
    "**Example: Pandas dataframe built from a Microsoft Excel spreadsheet:**<br>\n",
    "\n",
    "    sheet=0                               # the name (if given) or position number of the sheet to be read\n",
    "                                          # in the spreadsheet file spec'd by file path ss_file. Default is first (0)\n",
    "\n",
    "    df = pd.read_excel(ss_file, sheet_name=sheet)\n",
    "    \n",
    "    \n",
    "**Example: Pandas dataframe built from a SQLite database table:**<br>\n",
    "\n",
    "    import sqlite3\n",
    "    con=sqlite3.connect(db_name)\n",
    "    df = pd.read_sql_query(\"SELECT * from \"+tbl_name, con)\n",
    "    con.close()\n",
    "    \n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e.) Creating an instance of the SedSAS Class: <a name=\"instantiatingclass\"></a>\n",
    "\n",
    "When you instantiate the SedSASampleClass in your project you will send a copy of the Pandas dataframe that you create from your raw data, along with a sample id, and sieve screen size (mesh) list to the constructor (__init__) method. The calls to load and instantiate the class looks like this (Python code is italicized):\n",
    "\n",
    "    import SedSASClass* <br>\n",
    "    sc = SedSASClass.SedSAS(df, id)\n",
    "\n",
    "** Note that you must create an instance (only need one) of SedSAS before you can call any of its methods (functions)**\n",
    "\n",
    "** Also note that SedSAS only accepts and processes a SINGLE SAMPLE AT A TIME. If you want to batch process you\n",
    "can set up your code in a for-loop structure with an instance of SedSAS created with each loop iteration--very important!**\n",
    "\n",
    "The example notebooks in this repository demonstrates instantiation, and further usage of the SedSAS class methods in greater detail.\n",
    "\n",
    "\n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: User-Callable Class Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method: ComputeGSStats <a name=\"convenience\"></a>\n",
    "\n",
    "ComputeGSStats is a convenience method that combines methods ComputeFWLogInclusiveGraphicsStats, ComputeMcCammonHiEffGraphicStats, and ComputeLogarithmicMethodofMomentsStats into a single call. \n",
    "\n",
    "**call:** st=sc.ComputeGSStats( return_description=False)\n",
    "\n",
    "where sc is an instance of the SedSAS class.\n",
    "\n",
    "**Input args:** return_description: optionally return textural description of statistic as defined by Wentworth, (1922), and Folk and Ward (1957). Default is False.\n",
    "<br>\n",
    "\n",
    "**Returns:** Python list containing [0]=mean, [1]=sorting. Optionally, returns textural descriptors.\n",
    "<br>      \n",
    "\n",
    "**Returned units:** $\\phi$ for mean and sorting.<br>\n",
    "\n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method: ComputeFWLogInclusiveGraphicsStats <a name=\"log graphic stats\"></a> \n",
    "\n",
    "computes the logarithmic \"graphic\" mean, inclusive standard deviation (sorting), inclusive skewness, and kurtosis (per Folk and Ward, 1957; Folk, 1980; and many others) for a given sample. These are the classic graphically-generated particle-size statistics used throughout geomorphology, sedimentology, and soil science.\n",
    "\n",
    "<br>\n",
    "**call:** gs=sc.ComputeFWLogInclusiveGraphicsStats( return_description=False )\n",
    "\n",
    "sc. is the class instance\n",
    "\n",
    "**Input args:** return_description: optionally return textural description of statistic as defined by Wentworth, (1922), Folk and Ward (1957) and Blott and Pye (2001). Default is False.\n",
    "<br>\n",
    "\n",
    "**Returns:** Python list containing [0]=mean, [1]=sorting, [2]=skewness, [3]=kurtosis. Optionally, returns textural descriptors.\n",
    "<br>      \n",
    "\n",
    "**Returned units:** $\\phi$ for mean and sorting, none for skewness and kurtosis\n",
    "\n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method: ComputeMcCammonHiEffGraphicStats <a name=\"geom graphic stats\"></a> \n",
    "\n",
    "computes the  \"graphic\" mean, and standard deviation (per McCammon, 1963) for a given transect sample.\n",
    "<br>\n",
    "\n",
    "**call:** gs=sc.ComputeMcCammonHiEffGraphicStats( return_description=False )\n",
    "\n",
    "sc. is the class instance\n",
    "<br>\n",
    "\n",
    "**Input args:** return_description: optionally return textural description of statistic as defined by Wentworth (1922) and Folk and Ward (1957). Default is False.\n",
    "<br>\n",
    "\n",
    "**Returns:** Python list containing [0]=mean, [1]=sorting. Optionally, returns textural descriptors.\n",
    "<br>          \n",
    "\n",
    "**Returned units:** $\\phi$ for mean and sorting\n",
    "\n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method: ComputeArithmeticMethodofMomentsStats <a name=\"arithmetic moment stats\"></a> \n",
    "\n",
    "computes the mean, standard deviation, skewness, and kurtosis for a given transect sample using the Arithmetic Method of Momments (Friedman, 1962).\n",
    "<br>\n",
    "\n",
    "**call:** gs=sc.ComputeArithmeticMethodofMomentsStats( )\n",
    "\n",
    "sc. is the class instance\n",
    "<br>\n",
    "\n",
    "**Input args:** None\n",
    "<br>\n",
    "\n",
    "**Returns:** Python list containing [0]=mean, [1]=sorting, [2]=skewness, [3]=kurtosis\n",
    "<br>      \n",
    "\n",
    "**Returned units:** mm for mean and sorting, none for skewness and kurtosis\n",
    "\n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method: ComputeLogarithmicMethodofMomentsStats <a name=\"logrithmic moment stats\"></a> \n",
    "\n",
    "computes the mean, standard deviation, skewness, and kurtosis for a given transect sample using Geometric Method of Momments (Blott and Pye, 2001).\n",
    "<br>\n",
    "\n",
    "**call:** gs=sc.ComputeLogarithmicMethodofMomentsStats( return_description=False )\n",
    "\n",
    "sc. is the class instance\n",
    "<br>\n",
    "\n",
    "**Input args:** return_description: optionally return textural description of statistic as defined by Udden (1922), Krumbien and Pettijohn (1928), Folk and Ward (1957) anbd others. Default is False.\n",
    "<br>\n",
    "\n",
    "**Returns:** Python list containing [0]=mean, [1]=sorting, [2]=skewness, [3]=kurtosis. Optionally, returns textural descriptors.\n",
    "<br>      \n",
    "\n",
    "**Returned units:** $\\phi$ for mean and sorting, none for skewness and kurtosis\n",
    "\n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method: FindSampleModes <a name=\"sample modes\"></a> \n",
    "\n",
    "locates any, up to the first three, modal weight percentage values in current sample. \n",
    "<br>\n",
    "\n",
    "**call:** modes = sc.FindSampleModes()\n",
    "<br>\n",
    "\n",
    "**Input args:** None\n",
    "\n",
    "\n",
    "**Returns:** Python tuple of modes (if any) found in the current sample. The 0th item contains the mode in phi size \n",
    "units. The 1st item is the mode in mm. Up to the first three modes, if they exist, are reported in $\\phi$ and mm units\n",
    "                    \n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method: PLOTSampleWtPercents <a name=\"plot sample weight percents\"></a> \n",
    "\n",
    "plots the individual sample weight percentages, by sieve fraction as a histogram and overprinted frequency (PDF) curve for the current sample. Can plot to console or to stored PNG file.\n",
    "\n",
    "**call:** sc.PLOTSampleWtPercents(printTo='console')\n",
    "\n",
    "**Input args:** \n",
    "    printTo = plot destination: ='console' writes file output to the monitor (default) ; ='file' writes plot to a Portable Network Graphics (png) file\n",
    "    <br>\n",
    "     \n",
    "**Returns:** none\n",
    "                                               \n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method: PLOTSampleCumWtPercents <a name=\"plot cum weight percents\"></a> \n",
    "\n",
    "plots the individual sample cumulative weight percentages, by sieve fraction as a cumulative frequency (CDF) curve for the current transect sample. Can plot to console or to stored PNG file.\n",
    "\n",
    "**call:** sc.PLOTSampleCumWtPercents(printTo='console')\n",
    "\n",
    "**Input args:** \n",
    "    printTo = plot destination: ='console' writes file output to the monitor (default) ; ='file' writes plot to a Portable Network Graphics (png) file\n",
    "    <br>\n",
    "    \n",
    "**Returns:** none\n",
    "            \n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method: PLOTDualSampleWeightPercents <a name=\"plot dual sample weights\"></a> \n",
    "\n",
    "plots both the weight percentage and cumulative weight percentage histogram and curves (histo+PDF, and CDF) side by side and together, by sieve fraction for the current transect sample. Can plot to console or to stored PNG file.\n",
    "\n",
    "**call:** sc.PLOTDualSampleWeightPercents(printTo='console')\n",
    "\n",
    "**Input args:** \n",
    "    printTo = plot destination: ='console' writes file output to the monitor (default) ; ='file' writes plot to a Portable Network Graphics (png) file\n",
    "    <br>\n",
    "    \n",
    "**Returns:** none\n",
    "\n",
    "Note: This is just a convenient combination of methods PLOTSampleWtPercents and PLOTSampleCumWtPercents.\n",
    "                \n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method: ReturnQuantiles <a name=\"ReturnQuantiles\"></a> \n",
    "\n",
    "Returns a Python list, sorted ascending, of the standard quantile set required for the Folka nd Ward inclusive graphics computations: (5th, 10th, 16th, 25th, 50th, 75th, 86th, 90th, and 95th quantiles).\n",
    "\n",
    "**Input args:** None\n",
    "\n",
    "**Returns:** Python list of quantiles\n",
    "\n",
    "**Return Units:** $\\phi$\n",
    "            \n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method: ReturnWeightsData <a name=\"ReturnWeightsData\"></a>\n",
    "\n",
    "Returns a copy of the internal pandas data frame used for analysis and plotting..\n",
    "\n",
    "**call:** sc.ReturnWeightsData()\n",
    "\n",
    "**Input args:** None\n",
    "\n",
    "**Returns:** Pandas data frame\n",
    "\n",
    "**Return Units:** $\\phi$, mm, gms, etc.\n",
    "            \n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Notebooks <a name=\"sample scripts\"></a> \n",
    "\n",
    "The following are a set of Jupyter notebooks for use as a resource in learning to use SedSAS. These notebooks, which accompany this reference in the SedSAS GitHub repository, can be used for production work with, in many instances, only minor alterations. \n",
    "\n",
    "SedSAS_via_Direct_User_Input.ipynb: Computing statistics for a single sample, where the sample data are hand-entered by the user\n",
    "\n",
    "SedSAS_via_csv_File_Input.ipynb: Computing statistics for samples read from a comma-separated text file\n",
    "\n",
    "SedSAS_via_xlsx_File_Input.ipynb: Computing statistics for samples read from a Microsoft Excel spreadsheet\n",
    "\n",
    "SedSAS_via_SQLite_table_Input.ipynb: Computing statistics for samples read from a SQLite database\n",
    "\n",
    "        \n",
    "[Back to Guide](#Guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
