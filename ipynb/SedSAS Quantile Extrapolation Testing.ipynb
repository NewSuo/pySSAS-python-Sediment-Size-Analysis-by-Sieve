{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SedSAS - Quantile Extrapolation Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests the accuracy of extrapolation approach(es) used to generate quantile values from cumulative weight curves when the data is undetermined (partially bounded) for one or more of the requisite quantile values.\n",
    "\n",
    "It is common when dry sieving sediment in geologic particle size analyses to capture excess material in the largest aperture sieve, or find an excess of sediments falling through below the smallest aperture into the collection pan at the bottom of the stack. By excess we mean an amount that, when compiling the sample's cumuative weight density curve the data endpoints do not extend sufficiently such that all quantiles required for moment computations can be determined via interpolation methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the required Python libraries, modules, and magics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append( '/Users/paulp/GoogleDrive/projects/SedSAS' )\n",
    "import SedSASClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Data:\n",
    "\n",
    "Data comes from two sources. First, a weights file (./PINWR_Coarse_Sieve_Weights.txt) has been created containing selected Pea Island Beach Monitoring samples which have been resieved using a modified stack that includes several gravel-class fractions. The samples sieved were selected based on the amount of extrapolation required to generate the quantile set required for grain-size moment statistics computations. In the specfic case of these samples, all nine quantiles required extrapolation. \n",
    "\n",
    "The second source are the survey raw weight files compiled during initial dry sieving operations. These files are located in my GoogleDrive space at: ./projects/PeaIslandBeachMonitoring/data/FinalDataSets/Beach_Sand_Grain_Size (formatted as: PINWR_'survey date'_GrainSizeWeights). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'Survey'</th>\n",
       "      <th>'Transect'</th>\n",
       "      <th>'Sample'</th>\n",
       "      <th>'phi-4.5'</th>\n",
       "      <th>'phi-4'</th>\n",
       "      <th>'phi-3'</th>\n",
       "      <th>'phi-2.25'</th>\n",
       "      <th>'phi-2'</th>\n",
       "      <th>'phi-1'</th>\n",
       "      <th>'pan'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201407</td>\n",
       "      <td>C10</td>\n",
       "      <td>S1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>12.51</td>\n",
       "      <td>8.14</td>\n",
       "      <td>41.91</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201407</td>\n",
       "      <td>T15</td>\n",
       "      <td>S1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>6.49</td>\n",
       "      <td>3.42</td>\n",
       "      <td>24.29</td>\n",
       "      <td>34.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201407</td>\n",
       "      <td>C9</td>\n",
       "      <td>S1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.38</td>\n",
       "      <td>31.51</td>\n",
       "      <td>32.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   'Survey' 'Transect' 'Sample'  'phi-4.5'  'phi-4'  'phi-3'  'phi-2.25'  \\\n",
       "0    201407        C10       S1        0.0      0.0     2.37       12.51   \n",
       "1    201407        T15       S1        0.0      0.0     0.89        6.49   \n",
       "2    201407         C9       S1        0.0      0.0     1.39        3.98   \n",
       "\n",
       "   'phi-2'  'phi-1'  'pan'  \n",
       "0     8.14    41.91   2.91  \n",
       "1     3.42    24.29  34.31  \n",
       "2     3.38    31.51  32.92  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp='/Users/paulp/GoogleDrive/projects/PeaIslandBeachMonitoring/data/FinalDataSets/Beach_Sand_Grain_Size/'\n",
    "\n",
    "# read in the coarse sieve fraction data...\n",
    "dfB=pd.read_csv('./PINWR_Coarse_Sieve_Weights.txt')\n",
    "dfB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sheet_code sample_date transect_id sample_number  pan_weight  \\\n",
      "36  july2014_C10     7/15/14         C10            S1       11.51   \n",
      "\n",
      "    pan+wet_weight  pan+dry_weight  phi_-1  phi_-0,5  phi_0    ...      phi_1  \\\n",
      "36           73.42           67.67   65.05      2.33   0.06    ...       0.01   \n",
      "\n",
      "    phi_1,25  phi_1,5  phi_1,75  phi_2  phi_2,5  phi_3  phi_3,5  phi_4  \\\n",
      "36      0.01     0.01      0.01   0.01     0.01   0.01     0.01    NaN   \n",
      "\n",
      "    remainder  \n",
      "36        0.0  \n",
      "\n",
      "[1 rows x 21 columns]\n",
      "       sheet_code sample_date transect_id sample_number  pan_weight  \\\n",
      "100  july2014_T15     7/15/14         T15            S1        5.67   \n",
      "\n",
      "     pan+wet_weight  pan+dry_weight  phi_-1  phi_-0,5  phi_0    ...      \\\n",
      "100           74.45             NaN   35.67     14.86  11.83    ...       \n",
      "\n",
      "     phi_1  phi_1,25  phi_1,5  phi_1,75  phi_2  phi_2,5  phi_3  phi_3,5  \\\n",
      "100   0.94      0.17     0.22      0.26   0.43     0.12   0.05     0.01   \n",
      "\n",
      "     phi_4  remainder  \n",
      "100    NaN       0.03  \n",
      "\n",
      "[1 rows x 21 columns]\n",
      "     sheet_code sample_date transect_id sample_number  pan_weight  \\\n",
      "32  july2014_C9     7/15/14          C9            S1       11.47   \n",
      "\n",
      "    pan+wet_weight  pan+dry_weight  phi_-1  phi_-0,5  phi_0    ...      phi_1  \\\n",
      "32             0.0             NaN   41.63      21.1   8.52    ...       0.05   \n",
      "\n",
      "    phi_1,25  phi_1,5  phi_1,75  phi_2  phi_2,5  phi_3  phi_3,5  phi_4  \\\n",
      "32      0.01     0.01      0.03   0.04     0.01   0.01     0.01    NaN   \n",
      "\n",
      "    remainder  \n",
      "32       0.04  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "for index, row in dfB.iterrows():\n",
    "    survey=row[0]\n",
    "    transect=row[1]\n",
    "    sample=row[2]\n",
    "    dataB=list( row[3:] )\n",
    "    dfA=pd.read_csv(fp+'PINWR_'+str(survey)+'_GrainSizeWeights.csv')\n",
    "    \n",
    "    #recA=dfA.loc[(dfA['transect_id'].as == 'C10')]\n",
    "    recA=dfA[(dfA['transect_id'] == transect) & (dfA['sample_number']==sample)]\n",
    "\n",
    "    print(recA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.54000000000003\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi-4.5</th>\n",
       "      <th>phi-4</th>\n",
       "      <th>phi-3</th>\n",
       "      <th>phi-2.25</th>\n",
       "      <th>phi-2</th>\n",
       "      <th>phi-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Wgt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>12.51</td>\n",
       "      <td>8.14</td>\n",
       "      <td>41.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     phi-4.5  phi-4  phi-3  phi-2.25  phi-2  phi-1\n",
       "Wgt      0.0    0.0   2.37     12.51   8.14  41.91"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sheet_code,sample_date,transect_id,sample_number,pan_weight,pan+wet_weight,\n",
    "# pan+dry_weight,phi_-1,\"phi_-0,5\",phi_0,\"phi_0,5\",phi_1,\"phi_1,25\",\"phi_1,5\",\n",
    "# \"phi_1,75\",phi_2,\"phi_2,5\",phi_3,\"phi_3,5\",phi_4,remainder\n",
    "\n",
    "hdrA=[ 'phi-1','phi-0.5','phi 0','phi 0.5','phi 1','phi 1.25','phi 1.5',\n",
    "     'phi 1.75','phi 2','phi 2.5','phi 3','phi 3.5','phi 4','pan' ]\n",
    "hdrB=['phi-4.5','phi-4','phi-3','phi-2.25','phi-2','phi-1']\n",
    "screensA=[-1.0,-0.5,0.0,0.5,1.0,1.25,1.50,1.75,2.0,2.5,3.0,3.5,4.0,5.0]\n",
    "screensB=[-4.5,-4.0,-3.0,-2.25,-2.0]\n",
    "\n",
    "A=[ 65.05,2.33,0.06,0.02,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.0,0.00 ]\n",
    "B=[ 0.0,0.0,2.37,12.51,8.14,41.91]   #,41.91,2.91 ]\n",
    "\n",
    "print(sum(A))\n",
    "#print(sum(B))\n",
    "\n",
    "dfA=pd.DataFrame( {'Wgt':A} ).T\n",
    "dfA.columns=hdrA\n",
    "\n",
    "dfB=pd.DataFrame( {'Wgt':B} ).T\n",
    "dfB.columns=hdrB\n",
    "dfB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate SedSAS class instance for dataframe dfA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Particle-Size Composition Analysis. Processing Sample ID: 1\n",
      "----------------------------------------------------------------------\n",
      "WARNING: percent of undifferentiated coarse fraction in sample 1 is: 96.31 percent. This exceeds 5% of total by weight--values in excess of 5% can introduce significant error in the analysis. \n",
      "\n",
      "NOTE THAT ONE OR MORE QUANTILE VALUES MUST BE DETERMINED BY EXTRAPOLATION. \n",
      "\n",
      "Warning: 5% quantile < min cum wt%, extrapolating solution\n",
      "Warning: 10% quantile < min cum wt%, extrapolating solution\n",
      "Warning: 16% quantile < min cum wt%, extrapolating solution\n",
      "Warning: 25% quantile < min cum wt%, extrapolating solution\n",
      "Warning: 50% quantile < min cum wt%, extrapolating solution\n",
      "Warning: 75% quantile < min cum wt%, extrapolating solution\n",
      "Warning: 84% quantile < min cum wt%, extrapolating solution\n",
      "Warning: 90% quantile < min cum wt%, extrapolating solution\n",
      "Warning: 95% quantile < min cum wt%, extrapolating solution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-1.948, -1.896, -1.834, -1.74, -1.481, -1.221, -1.128, -1.066, -1.014],\n",
       " [3.859, 3.722, 3.565, 3.341, 2.791, 2.332, 2.185, 2.093, 2.019])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssc=SedSASClass.SedSAS('1', dfA, screensA)\n",
    "qntA=ssc.GetQuantileList()\n",
    "qntA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate SedSAS class instance for dataframe df = dfA + dfB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Particle-Size Composition Analysis. Processing Sample ID: 2\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-2.94, -2.738, -2.495, -2.189, -1.745, -1.343, -1.198, -1.101, -1.021],\n",
       " [7.674, 6.671, 5.639, 4.561, 3.352, 2.536, 2.294, 2.146, 2.029])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screensB.extend(screensA)\n",
    "df=pd.concat( [dfB,dfA.iloc[:,1:] ], axis=1 )\n",
    "\n",
    "ssc2=SedSASClass.SedSAS('2', df, screensB)\n",
    "qntf=ssc2.GetQuantileList()\n",
    "qntf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.992,  0.842,  0.661,  0.449,  0.264,  0.122,  0.07 ,  0.035,\n",
       "         0.007],\n",
       "       [-3.815, -2.949, -2.074, -1.22 , -0.561, -0.204, -0.109, -0.053,\n",
       "        -0.01 ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.subtract(qntA,qntf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
